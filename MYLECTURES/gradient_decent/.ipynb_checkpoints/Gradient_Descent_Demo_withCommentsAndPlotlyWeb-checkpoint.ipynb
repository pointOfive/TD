{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy.spatial.distance import norm\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "import time\n",
    "\n",
    "tls.set_credentials_file(username='', api_key='')\n",
    "\n",
    "def gradient_descent(X, y, \n",
    "                     cost_function, # The cost function from which we'll calculate the cost. \n",
    "                     gradient_of_cost_function, # The function that we'll use to calculate the gradient. \n",
    "                     initial_guess, # Our initial parameters.\n",
    "                     learning_rate=.1, # This is the step size.\n",
    "                     threshold=1e-3, # When the gradient gets this flat, stop.\n",
    "                     max_iter=1e3): # How may times we're willing to take a step.\n",
    "    \n",
    "    \n",
    "    params = initial_guess\n",
    "        # We keep track of the previous parameters. We store a tuple with our initial guess\n",
    "        # and the cost. The number of parameters is hard coded to be 2. This is\n",
    "        # not a general purpose gradient descent function. We will be returning the \n",
    "        # the parameter history, not just the final parameters. This is so that we can\n",
    "        # compare how well this version of gradient descent converges compared to other \n",
    "        # versions.\n",
    "    param_history = [(initial_guess[0], initial_guess[1], cost_function(X, y, params))]\n",
    "        # improvement = (cost_old-cost_new)/cost_old. This may not make sense if the is ever\n",
    "        # close to zero. The function doesn't actually use this parameter.\n",
    "    improvement = threshold\n",
    "        # Start the cost at something high so that it can only get smaller. Probably\n",
    "        # better to start it at float('inf')\n",
    "    old_cost = 100000\n",
    "        # The starting value for our index.\n",
    "    iterations = 0\n",
    "        # We keep track of how long each iteration takes. \n",
    "    initial_time = time.time()\n",
    "    time_history = []\n",
    "    #time_history = [time.time()]\n",
    "        # When the gradient is big, keep descending. However, if the number of iterations\n",
    "        # becomes equal to the maximum number, max_iter, stop. This prevents us from getting\n",
    "        # stuck in an infinite loop.\n",
    "    \n",
    "    while (norm(gradient_of_cost_function(X, y, params)) >= threshold \n",
    "           and iterations < max_iter):\n",
    "        iterations += 1\n",
    "            # Here we calculate the step size and store it in params.\n",
    "        params -= learning_rate*gradient_of_cost_function(X, y, params)\n",
    "            # We calculate the current cost and store it in a temporary variable.\n",
    "        cost = cost_function(X, y, params)\n",
    "            # Because this next line uses params[0] and params[1], we know that this funtion\n",
    "            # is hard coded to do gradient descent with two parameters. \n",
    "            # We will eventually be graphing time vs cost.\n",
    "        param_history.append((params[0], params[1], cost)) # for plotting\n",
    "            # This is how much the cost function improved compared to previously.\n",
    "            # There could be a problem if the old cost is zero. But in linear regression, \n",
    "            # the cost is strictly positive. \n",
    "        improvement = np.abs(cost - old_cost)/old_cost\n",
    "            # update the old cost to be the current one for the next iteration.\n",
    "        old_cost = cost\n",
    "            # keep track of the time at which this iteration happened. This is for graphing.\n",
    "        #time_history.append(time.time())\n",
    "        time_history.append(time.time()-initial_time)\n",
    "        \n",
    "        # This next couple of lines just tells us if we reached the maximum number of iterations.\n",
    "        # If we did, print it. This is important because in this case we may not have actually\n",
    "        # reached a solution.\n",
    "    if iterations == max_iter:\n",
    "        print \"max iterations reached\"\n",
    "    print \"Final gradient of cost function %s\" %gradient_of_cost_function(X, y, params)\n",
    "    print \"Final params %s\" %params\n",
    "    \n",
    "        # We return not just the parameters, but the history of parameters.\n",
    "    return param_history, time_history\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(X, y, \n",
    "                     cost_function, # The cost function\n",
    "                     gradient_of_cost_function, # The gradient cost function.\n",
    "                     initial_guess, # Our initial guess for the answer. \n",
    "                     learning_rate=.1, # The step size. \n",
    "                     threshold=1e-3, # If the gradient is flatter than this, stop.\n",
    "                     max_iter=1e3, # If we step more than this number of times, stop.\n",
    "                     batch_size=1): # The number of data points used to calculate the gradient.\n",
    "    \n",
    "        # We can't have a batch size that is bigger than the number of data point. We check for this\n",
    "        # in the next line. \n",
    "    batch_size = min(batch_size, X.shape[0])\n",
    "        # Relabeling our parameters. \n",
    "    params = initial_guess\n",
    "        # The gradient descent function above also kept track of the cost function. \n",
    "        # The function returns param_history.\n",
    "    param_history = [(initial_guess[0], initial_guess[1])]\n",
    "        # improvement = (cost_new - cost_old)/cost_old\n",
    "    improvement = threshold\n",
    "        # the initial cost. This is rather arbitrary. I would choose it to be float('inf')\n",
    "    old_cost = 100000\n",
    "        # We keep track of how many times we have gone through our loop with the iterations\n",
    "        # variable. We will add one to it every time we go through the while loop.\n",
    "    iterations = 0\n",
    "        # We clock our initial time. We will return this list. \n",
    "    #time_history = [time.time()]\n",
    "    initial_time = time.time()\n",
    "    time_history = []\n",
    "    \n",
    "        # When the gradient is steep enough and we haven't reached our threshold for\n",
    "        # how many iterations we're willing to do, then go down the hill.\n",
    "    while (norm(gradient_of_cost_function(X, y, params)) >= threshold \n",
    "           and iterations < max_iter):\n",
    "        # select indices of mini-batch\n",
    "            # I am not really sure what this does yet.\n",
    "            # If the iteration is zero, then the min_index is zero. If iteration=1, then the \n",
    "            # min_index = batch_size. So what we are doing is splitting the data into groups.\n",
    "            # They are not random groups though. \n",
    "        min_index = batch_size*iterations % X.shape[0]\n",
    "        indices = []\n",
    "            # Fill up the indices for the next batch.\n",
    "        while len(indices) < batch_size:\n",
    "            indices.append((min_index + len(indices)) % X.shape[0])\n",
    "        Xi, yi = X[indices], y[indices]\n",
    "        # update parameters\n",
    "        params -= learning_rate*gradient_of_cost_function(Xi, yi, params)\n",
    "        cost = cost_function(Xi, yi, params)\n",
    "        param_history.append((params[0], params[1])) # for plotting\n",
    "        improvement = np.abs(cost - old_cost)/old_cost\n",
    "        old_cost = cost\n",
    "        iterations += 1\n",
    "        time_history.append(time.time()-initial_time)\n",
    "    if iterations == max_iter:\n",
    "        print \"max iterations reached\"\n",
    "    print \"Final gradient of cost function %s\" %gradient_of_cost_function(X, y, params)\n",
    "    print \"Final params %s\" %params\n",
    "    return param_history, time_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_results(X, y, cost_function, param_history):\n",
    "    params = param_history[-1][0:2]\n",
    "    x_params = np.array([params[0] - (params[0]-p[0]) for p in param_history] +\n",
    "                [params[0] + (params[0]-p[0]) for p in param_history])\n",
    "    x_params.sort()\n",
    "    y_params = np.array([params[1] - (params[1]-p[1]) for p in param_history] +\n",
    "                [params[1] + (params[1]-p[1]) for p in param_history])\n",
    "    y_params.sort()\n",
    "    samples = list(product(x_params, y_params))\n",
    "    costs = [cost_function(X, y, np.array([p[0], p[1]])) for p in samples]\n",
    "    costs = np.reshape(costs, (len(x_params), -1))\n",
    "    cost_surface = Surface(\n",
    "        x = x_params,\n",
    "        y = y_params,\n",
    "        z = costs,\n",
    "        colorscale = [[0, 'rgb(31,119,180)'], \n",
    "                      [0.5, 'rgb(143, 123, 196)'], \n",
    "                      [1, 'rgb(255,127,97)']],\n",
    "        name='Cost Function'\n",
    "    )\n",
    "    param_history = Scatter3d(\n",
    "        x = x_params,\n",
    "        y = y_params,\n",
    "        z = [p[2] for p in param_history],\n",
    "        mode = 'lines+markers'\n",
    "    )\n",
    "    data_3d_plot = Data([cost_surface, param_history])\n",
    "    figure_3d = Figure(data=data_3d_plot)\n",
    "    return figure_3d\n",
    "\n",
    "def plot_sgd_results(X, y, cost_function, param_history):\n",
    "    x_history = [p[0] for p in param_history]\n",
    "    y_history = [p[1] for p in param_history]\n",
    "    x_params = np.linspace(min(x_history),\n",
    "                           max(x_history),\n",
    "                           100)\n",
    "    y_params = np.linspace(min(y_history),\n",
    "                           max(y_history),\n",
    "                           100)\n",
    "    samples = list(product(x_params, y_params))\n",
    "    demo_points = OrderedDict()\n",
    "    for p in param_history:\n",
    "        best_sample = samples[0]\n",
    "        min_distance = ((p[0]-best_sample[0])**2+(p[1]-best_sample[1])**2)**.5\n",
    "        for sample in samples:\n",
    "            d = ((p[0]-sample[0])**2+(p[1]-sample[1])**2)**.5\n",
    "            if d < min_distance:\n",
    "                best_sample = sample\n",
    "                min_distance = d\n",
    "        demo_points[tuple(p)] = best_sample\n",
    "    costs = [cost_function(X, y, np.array([p[0], p[1]])) for p in samples]\n",
    "    costs = np.reshape(costs, (len(x_params), -1))\n",
    "    cost_surface = Surface(\n",
    "        x = x_params,\n",
    "        y = y_params,\n",
    "        z = costs,\n",
    "        colorscale = [[0, 'rgb(31,119,180)'], \n",
    "                      [0.5, 'rgb(143, 123, 196)'], \n",
    "                      [1, 'rgb(255,127,97)']],\n",
    "        name='Cost Function'\n",
    "    )\n",
    "    param_history = Scatter3d(\n",
    "        x = [d[0] for d in demo_points],\n",
    "        y = [d[1] for d in demo_points],\n",
    "        z = [cost_function(X, y, d) for d in demo_points],\n",
    "        mode = 'lines+markers'\n",
    "    )\n",
    "    data_3d_plot = Data([cost_surface, param_history])\n",
    "    figure_3d = Figure(data=data_3d_plot)\n",
    "    return figure_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(X, params):\n",
    "    y_predicted = X.dot(params)\n",
    "    return y_predicted\n",
    "\n",
    "    # make_regression is a sub-module from sklearn. We're using it to generate data. \n",
    "X, y = make_regression(n_samples = 50, n_features = 2, n_informative=2, random_state=0)\n",
    "\n",
    "    # The next line normalizes the data.\n",
    "X = (X - X.mean(axis=0))/X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the data in a 3-d graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADtCAYAAAAcNaZ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5f8DaGyCx0CKlR4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a03e590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xs = X[:,0]\n",
    "ys = X[:,1]\n",
    "zs = y\n",
    "ax.scatter(xs, ys, zs, c='b')\n",
    "\n",
    "ax.set_xlabel('X_1')\n",
    "ax.set_ylabel('X_2')\n",
    "ax.set_zlabel('Y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we do gradient descent on the half average sum of squares cost function, RSS/(2n)\n",
      "The graph is of both the cost function and a history of parameters.\n",
      "\n",
      "Final gradient of cost function [-0.00036218 -0.00086667]\n",
      "Final params [ 42.71922179  61.1163727 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/120.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR REGRESSION WITHOUT REGULARIZATION\n",
    "\n",
    "def ols_cost_function(X, y, params):\n",
    "    '''\n",
    "    OLS from linear regression\n",
    "    '''\n",
    "        # Get the number of rows in our data.\n",
    "    n_observations = X.shape[0]\n",
    "        # Average square of the residual. RSS/n. I don't understand why the extra factor of 2?\n",
    "        # I think it is over 2 so that the gradient has no factor of two. So this is really\n",
    "        # half of the average of the residuals. \n",
    "    avg_squared_residuals = ((predict(X, params) - y)**2).sum()/(2*n_observations)\n",
    "    return avg_squared_residuals\n",
    "\n",
    "def ols_gradient_of_cost_function(X, y, params):\n",
    "        # The number of rows in our data. \n",
    "    n_observations = X.shape[0]\n",
    "        # The gradient of the RSS/(2n) cost function.\n",
    "    gradient = (predict(X, params) - y).dot(X)/n_observations\n",
    "    return gradient\n",
    "\n",
    "\n",
    "print \"Here we do gradient descent on the half average sum of squares cost function, RSS/(2n)\"\n",
    "print \"The graph is of both the cost function and a history of parameters.\\n\"\n",
    "\n",
    "gd_param_history, gd_time_history = gradient_descent(X, y, \n",
    "                                                     ols_cost_function, \n",
    "                                                     ols_gradient_of_cost_function,\n",
    "                                                     learning_rate=.1, # The step size. \n",
    "                                                     threshold=1e-3,#\n",
    "                                                     initial_guess = np.array([0., 0.]))\n",
    "\n",
    "\n",
    "py.sign_in('schwarls37','q71kqamu80')\n",
    "\n",
    "figure_3d = plot_results(X, y, ols_cost_function, gd_param_history)\n",
    "tls.embed(py.plot(figure_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we do gradient descent on the ridge regression cost function.\n",
      "This is essentially the average sum of squares $+ \\lambda \\beta \\cdot \beta$\n",
      "The parameters are slightly smaller, by 2 or 3.\n",
      "\n",
      "\n",
      "Final gradient of cost function [-0.00034382 -0.00058411]\n",
      "Final params [ 10.64799024  14.46411654]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/132.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR REGRESSION WITH L2 REGULARIZATION\n",
    "\n",
    "LAMBDA_ = 15#150.\n",
    "\n",
    "def ridge_cost_function(X, y, params, lambda_=LAMBDA_):\n",
    "    '''\n",
    "    OLS from linear regression\n",
    "    '''\n",
    "    n_observations = X.shape[0]\n",
    "    avg_squared_residuals = (((predict(X, params) - y)**2).sum()\n",
    "                             + lambda_*(params**2).sum())/(2*n_observations)\n",
    "    return avg_squared_residuals\n",
    "\n",
    "def ridge_gradient_of_cost_function(X, y, params, lambda_=LAMBDA_):\n",
    "    n_observations = X.shape[0]\n",
    "    gradient = ((predict(X, params) - y).dot(X)\n",
    "               + lambda_*params)/n_observations\n",
    "    return gradient\n",
    "\n",
    "print \"Here we do gradient descent on the ridge regression cost function.\"\n",
    "print \"This is essentially the average sum of squares $+ \\lambda \\\\beta \\cdot \\beta$\"\n",
    "print \"The parameters are slightly smaller, by 2 or 3.\"\n",
    "print \"\\n\"\n",
    "\n",
    "\n",
    "ridge_param_history, ridge_time_history = gradient_descent(X, y, ridge_cost_function, ridge_gradient_of_cost_function,\n",
    "                                   initial_guess = np.array([0., 0.]))\n",
    "\n",
    "figure_3d = plot_results(X, y, ridge_cost_function, ridge_param_history)\n",
    "tls.embed(py.plot(figure_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we show the cost function for Lasso. This is like the average sum of squares with\n",
      "an additional piece to the cost function that penalizes bigger coefficeints. This is\n",
      "much like ridge regression but the cost is the sum of the absolute values of each of the\n",
      "coefficients. The result of the sum of absolute values is that the cost function is not\n",
      "longer differentiable everywhere. In particular, the gradient changes abruptly when\n",
      "$\beta_1 = 0$ or $\beta_2=0$. Because of this one has to be careful about how one defines\n",
      "the gradient at these points.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/136.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LASSO\n",
    "PARAM_HISTORY = [] \n",
    "\n",
    "LAMBDA_ = 350#3500.\n",
    "\n",
    "def lasso_cost_function(X, y, params, lambda_=LAMBDA_):\n",
    "    '''\n",
    "    OLS from linear regression\n",
    "    '''\n",
    "    n_observations = X.shape[0]\n",
    "    avg_squared_residuals = (((predict(X, params) - y)**2).sum()\n",
    "                             + lambda_*sum(np.abs(params)))/(2*n_observations)\n",
    "    return avg_squared_residuals\n",
    "\n",
    "x_params = np.linspace(-25, 75, 100)\n",
    "y_params = np.linspace(-25, 75, 100)\n",
    "samples = list(product(x_params, y_params))\n",
    "costs = [lasso_cost_function(X, y, np.array([p[0], p[1]])) for p in samples]\n",
    "costs = np.reshape(costs, (len(x_params), -1))\n",
    "cost_surface = Surface(\n",
    "    z = costs,\n",
    "    x = x_params,\n",
    "    y = y_params,\n",
    "    colorscale = [[0, 'rgb(31,119,180)'], \n",
    "                  [0.5, 'rgb(143, 123, 196)'], \n",
    "                  [1, 'rgb(255,127,97)']],\n",
    "    name='Cost Function'\n",
    ")\n",
    "\n",
    "print \"Here we show the cost function for Lasso. This is like the average sum of squares with\"\n",
    "print \"an additional piece to the cost function that penalizes bigger coefficeints. This is\"\n",
    "print \"much like ridge regression but the cost is the sum of the absolute values of each of the\"\n",
    "print \"coefficients. The result of the sum of absolute values is that the cost function is not\"\n",
    "print \"longer differentiable everywhere. In particular, the gradient changes abruptly when\"\n",
    "print \"$\\beta_1 = 0$ or $\\beta_2=0$. Because of this one has to be careful about how one defines\"\n",
    "print \"the gradient at these points.\"\n",
    "\n",
    "data_3d_plot = Data([cost_surface])\n",
    "figure_3d = Figure(data=data_3d_plot)\n",
    "tls.embed(py.plot(figure_3d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we do stochastic gradient descent. By default the batch size is 1. That is, we\n",
      "calculate the gradient from an individual data point. We plot the path that the\n",
      "parameters take. \n",
      "\n",
      "max iterations reached\n",
      "Final gradient of cost function [-1.33573467  0.45502579]\n",
      "Final params [ 41.45343437  61.55137444]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/138.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD: LINEAR REGRESSION\n",
    "\n",
    "print \"Here we do stochastic gradient descent. By default the batch size is 1. That is, we\"\n",
    "print \"calculate the gradient from an individual data point. We plot the path that the\"\n",
    "print \"parameters take. \\n\"\n",
    "\n",
    "    # The next line runs the stochastic gradient descent algorith.\n",
    "sgd_param_history, sgd_time_history = stochastic_gradient_descent(X, y, \n",
    "                                                            ols_cost_function, \n",
    "                                                            ols_gradient_of_cost_function,\n",
    "                                                            initial_guess=np.array([0., 0.]),\n",
    "                                                            learning_rate=.1)\n",
    "\n",
    "    # The next lines plot the results of stochastic gradient descent. \n",
    "figure_3d = plot_sgd_results(X, y, ols_cost_function, sgd_param_history)\n",
    "tls.embed(py.plot(figure_3d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we do mini-batch stochastic gradient descent for the average sum of squares cost function. Notice that the approach is much smoother. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max iterations reached\n",
      "Final gradient of cost function [-0.07039159  0.12712869]\n",
      "Final params [ 42.65627649  61.24856424]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/140.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MINIBATCH SGD: LINEAR REGRESSION WITHOUT REGULARIZATION\n",
    "minibatch_param_history, minibatch_time_history = stochastic_gradient_descent(X, y, ols_cost_function, \n",
    "                                                ols_gradient_of_cost_function,\n",
    "                                                initial_guess=np.array([0., 0.]),\n",
    "                                                learning_rate=.1, batch_size=5)\n",
    "figure_3d = plot_sgd_results(X, y, ols_cost_function, minibatch_param_history)\n",
    "tls.embed(py.plot(figure_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are plotting step vs log(Cost)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/142.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLOT GD, SGD, and minibatch SGD convergence on log scale\n",
    "gd_convergence = Scatter(\n",
    "    x = [i for i,j in enumerate(gd_param_history)],\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in gd_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'Batch Gradient Descent'\n",
    ")\n",
    "\n",
    "sgd_convergence = Scatter(\n",
    "    x = [i for i,j in enumerate(sgd_param_history)],\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in sgd_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'SGD'\n",
    ")\n",
    "\n",
    "minibatch_convergence = Scatter(\n",
    "    x = [i for i,j in enumerate(minibatch_param_history)],\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in minibatch_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'Mini-batch SGD'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    xaxis=XAxis(\n",
    "        range=[0,150]\n",
    "    ),\n",
    "    yaxis=YAxis(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "print \"We are plotting step vs log(Cost)\"\n",
    "\n",
    "data = Data([gd_convergence, sgd_convergence, minibatch_convergence])\n",
    "figure = Figure(data=data, layout=layout)\n",
    "tls.embed(py.plot(figure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are plotting step vs log(Cost)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~schwarls37/144.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLOT GD, SGD, and minibatch SGD convergence on log scale now with the cpu times. \n",
    "\n",
    "    # start each computation at zero. This may not be valid as the initial time was computed\n",
    "    # for each one. So subtracting the first entry from everything may not be valid. \n",
    "#gd_time_history = np.array(gd_time_history)-gd_time_history[0]\n",
    "#sgd_time_history = np.array(sgd_time_history)-sgd_time_history[0]\n",
    "#minibatch_time_history = np.array(minibatch_time_history) - minibatch_time_history[0]\n",
    "\n",
    "gd_convergence = Scatter(\n",
    "    x = gd_time_history,\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in gd_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'Batch Gradient Descent'\n",
    ")\n",
    "\n",
    "sgd_convergence = Scatter(\n",
    "    x = sgd_time_history,\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in sgd_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'SGD'\n",
    ")\n",
    "\n",
    "minibatch_convergence = Scatter(\n",
    "    x = minibatch_time_history,\n",
    "    y = [ols_cost_function(X, y, (p[0], p[1])) for p in minibatch_param_history],\n",
    "    mode = 'lines',\n",
    "    name = 'Mini-batch SGD'\n",
    ")\n",
    "\n",
    "layout = Layout(\n",
    "    xaxis=XAxis(\n",
    "        range=[0,.01]\n",
    "    ),\n",
    "    yaxis=YAxis(\n",
    "        type='log',\n",
    "        autorange=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "print \"We are plotting step vs log(Cost)\"\n",
    "\n",
    "data = Data([gd_convergence, sgd_convergence, minibatch_convergence])\n",
    "figure = Figure(data=data, layout=layout)\n",
    "tls.embed(py.plot(figure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0017781257629394531, 0.007359027862548828, 0.00032901763916015625)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_time_history[0],sgd_time_history[0],minibatch_time_history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
